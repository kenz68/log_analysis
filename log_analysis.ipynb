{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "PySpark tutorial for beginers\n",
    "\n",
    "This notebook is a part of my learning journey which I've been documenting from Udacity's Data Scientist Nanodegree program, which\n",
    "helped me a lot to learn and excel advanced data science stuff such as PySpark. Thank you so much Udacity for providing such quality\n",
    "content.\n",
    "\n",
    "Spark is a big data framework which contains libraries for data analysis, machine learning, graph analisis, and streaming live data. Spark\n",
    "is generally faster than Hadoop. This is because Hadoop writes intermidiate results to disk whereas Spark tries to keep intermediate\n",
    "results in memory whenever possible.\n",
    "\n",
    "The Hadoop ecosystem includes a distributed file storage system called HDFS (Hadoop Distributed File System). Spark, on the other\n",
    "hand, does not include a file storage system. You can use Spark on top of HDFS, but you do not have to. Spark can read in data from\n",
    "other sources as well such as Amazon S3.\n",
    "\n",
    "Spark doesn't implement MapReduce, you can write Spark programs that behave in a similar way to the map-reduce pattern.\n",
    "\n",
    "Limitations of Spark:\n",
    "\n",
    "    - Spark Streaming's latency is at least 500 milliseconds since it operates on micro-batches of records, instead of processing one\n",
    "    record at a time. Native streaming tools such as Storm, Apex, of Flink can push down this latency value and might be more suitable\n",
    "    for low-latency applications. Flink and Apex can be used for batch computation as well, so if you're already using them for stream\n",
    "    processing, there's no need to ass Spark to your stack of technologies.\n",
    "    \n",
    "    - Another limitation of Spark is its selection of machine learning algorithms. Currently, Spark only supports algorithms that scale\n",
    "    linerly with the input data size. In general, deep learning is not available either, though there are many projects integrate Spark\n",
    "    with Tensorflow and other deep learning tools.\n",
    "   \n",
    "Source: - Spark and PySpark documentation "
   ],
   "id": "26d55f778d85cad7"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-03T02:46:54.628202Z",
     "start_time": "2024-10-03T02:46:54.620087Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "for dirname, _, filenames in os.walk(os.getcwd() + \"\\input\"):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\00.bigdata\\src\\log_analysis\\log_analysis\\input\\sparkify_log_small.json\n"
     ]
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
